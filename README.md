# 🧠 VideoLLM – AISG Challenge Submission

> ⚠️ **Note:** 83 questions could not be answered due to missing videos.  
> 📌 These are currently marked as `"Not Available"` in the submission.  
> ✅ Alternatively, hallucinated answers can be generated by the model for better completeness.

---

## ⚙️ Development Environment

| Resource        | Specification         |
|----------------|------------------------|
| GPU            | NVIDIA H100 SXM (1x)   |
| GPU Memory     | 80 GB                  |
| Disk Space     | 100 GB                 |

---

## 📊 Model Performance (Correctness, Robustness)

Due to compute constraints, evaluations were primarily conducted on **Qwen2.5-VL 7B**.  
We estimate that **Qwen2.5-VL 32B** performs approximately **10–15% better**.

| Configuration                                                          | Correctness (%) | Robustness (%) |
|------------------------------------------------------------------------|-----------------|----------------|
| Qwen2.5-VL 7B + Prompt Tuning                                          | 27.47           | 5.5            |
| Qwen2.5-VL 32B + Prompt Tuning (Projected)                             | 40.33           | 23.0           |
| Qwen2.5-VL 7B + Prompt Tuning + Guess Missing Video (Base)             | 32.87           | 5.8            |
| Qwen2.5-VL 7B + Base + Higher FPS (1 → 5)                              | 🔧 Not Tested    | 🔧 Not Tested   |
| Qwen2.5-VL 7B + Base + External Evaluator Integration                  | 🔧 Not Tested    | 🔧 Not Tested   |
| Qwen2.5-VL 7B + Base + Audio Captioning via Whisper                    | 🔧 Not Tested    | 🔧 Not Tested   |
| Qwen2.5-VL 7B + Base + RNN Adapter for Recursive Video Understanding   | 🔧 Not Tested    | 🔧 Not Tested   |

---

## 🛠️ Future Work

- Evaluate RNN-based adapter architecture for improved temporal coherence  
- Incorporate Whisper captions directly into multimodal prompts  
- Build robust fallback strategies for missing/partial video data  
- Expand testing coverage on 32B checkpoints using more GPUs

---

For questions or collaboration, feel free to reach out. 🚀